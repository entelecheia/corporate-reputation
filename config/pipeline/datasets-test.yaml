defaults:
  - datasets

use_task_as_initial_object: true
steps:
  - uses: pipe_load_dataset
    with:
      data_dir: datasets/processed/kakao_filtered
      path: parquet
      split: train
    verbose: true
  - uses: pipe_sample
    with:
      sample_size: 15
      randomize: true
      verbose: true
  - uses: pipe_tokenize
    with:
      tokenizer_config_name: mecab
      # batch_size: 3
      num_workers: 1
      text_col: cleaned_text
      token_col: tokenizedText
      load_from_cache_file: false
      verbose: true
  - uses: pipe_extract
    with:
      tokenizer_config_name: kakao
      # batch_size: 3
      num_workers: 1
      token_col: tokenizedText
      nouns_only: true
      load_from_cache_file: false
      verbose: true
  - uses: pipe_save
    with:
      dataset_path: datasets/processed/kakao_nouns_test
    verbose: true
